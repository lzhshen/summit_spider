[
{"speakers": [{"bio": "", "corp": "Confluent", "name": "Neha Narkhede, Co-founder and CTO"}], "base_fname": "Go_Against_the_Flow_Databases_and_Stream_Processing", "title": "Go Against the Flow: Databases and Stream Processing", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/qvXxdcjUFjgPCO"}, "tag": "keynote", "video": {"dl_link": "http://r5---sn-n4v7sne7.googlevideo.com/videoplayback?dur=1213.149&id=o-AJ-h7XYBO7l5RrHyDF5SJuG38VbabvXjeyZFaNKi7Z5o&ei=F_zKWY-MDsKt-wPFzIi4DA&mn=sn-n4v7sne7&pl=19&signature=D5BF4C68FDB72A3B9D027D68869750FC45273782.54BEE53E65362C0862CD88248095DCC34D5DBC93&mm=31&expire=1506496631&lmt=1504199239968708&mt=1506474892&ip=162.243.140.150&initcwndbps=2038750&sparams=dur%2Cei%2Cid%2Cinitcwndbps%2Cip%2Cipbits%2Citag%2Clmt%2Cmime%2Cmm%2Cmn%2Cms%2Cmv%2Cpl%2Cratebypass%2Csource%2Cexpire&itag=22&key=yt6&source=youtube&mime=video%2Fmp4&ms=au&mv=m&ipbits=0&ratebypass=yes&title=Go_Against_the_Flow_Databases_and_Stream_Processing", "src_link": "https://www.youtube.com/embed/F3pJOg1uErQ?rel=0"}, "desc": ""},
{"speakers": [{"bio": "", "corp": "Salesforce", "name": "Pat Helland, Software Architect"}], "base_fname": "Standing_on_the_Distributed_Shoulders_of_Giants", "title": "Standing on the Distributed Shoulders of Giants", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/gYeIMI02b5UkD0"}, "tag": "keynote", "video": {"dl_link": "http://r6---sn-n4v7sn76.googlevideo.com/videoplayback?key=yt6&signature=C31EB41D0632C37640E1BED452210EE42D83A7A0.3AFE3AC9ABB6984F5FAA16F9C20CB88B68F1681E&id=o-ACQsMaBeB7jYjlQ55yhtikW4LHC05Fn-ZxnIKSaX0lwT&ei=vhbLWerWDc6P-wOfyJCQCw&mn=sn-n4v7sn76&mm=31&ipbits=0&initcwndbps=2035000&ratebypass=yes&pl=48&mime=video%2Fmp4&sparams=dur%2Cei%2Cid%2Cinitcwndbps%2Cip%2Cipbits%2Citag%2Clmt%2Cmime%2Cmm%2Cmn%2Cms%2Cmv%2Cpl%2Cratebypass%2Csource%2Cexpire&expire=1506503454&ip=2604%3Aa880%3A2%3Ad0%3A%3A496c%3Ad001&ms=au&itag=22&lmt=1504199433842883&mt=1506481659&dur=1193.784&mv=m&source=youtube&title=Standing_on_the_Distributed_Shoulders_of_Giants", "src_link": "https://www.youtube.com/embed/p9LBi11KR2c?rel=0"}, "desc": ""},
{"speakers": [{"bio": "", "corp": "Stitch Fix", "name": "Randy Shoup, VP of Engineering"}], "base_fname": "Managing_Data_at_Scale_The_Unreasonable_Effectiveness_of_Events", "title": "Managing Data at Scale: The Unreasonable Effectiveness of Events", "slide": {"dl_link": "", "src_link": "www.slideshare.net/slideshow/embed_code/key/2icc5mVdnoqo65"}, "tag": "keynote", "video": {"dl_link": "http://r2---sn-jvhnu5g-n8vk.googlevideo.com/videoplayback?source=youtube&mt=1506481659&mv=m&beids=%5B9466591%5D&ms=au&ip=85.235.173.42&key=yt6&dur=1150.316&itag=22&pl=19&mime=video%2Fmp4&mm=31&sparams=dur%2Cei%2Cid%2Cinitcwndbps%2Cip%2Cipbits%2Citag%2Clmt%2Cmime%2Cmm%2Cmn%2Cms%2Cmv%2Cpcm2cms%2Cpl%2Cratebypass%2Csource%2Cexpire&mn=sn-jvhnu5g-n8vk&id=o-AHRxq7ipajtPa86Tf-NkpNkZoH5lGqaZiy3A-zocujY1&expire=1506503462&ei=xhbLWdm0LIWOdaPotpAK&pcm2cms=yes&signature=306C0C22551AF05BEEA1C9905BA3E2ABAD81DE11.9EB2EA83071BDF740C81168A6E7B43EFC763136E&lmt=1504199520735370&ratebypass=yes&initcwndbps=840000&ipbits=0&title=Managing_Data_at_Scale_The_Unreasonable_Effectiveness_of_Events", "src_link": "https://www.youtube.com/embed/HZX8uYTwKls?rel=0"}, "desc": ""},
{"speakers": [{"bio": "", "corp": "Microsoft", "name": "Nitin Kumar, Principal Software Engineering Manager"}], "base_fname": "820366129", "title": "Providing Reliability Guarantees in Kafka at One Trillion Events Per Day", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/CC6qIhDFYvP2Dv"}, "tag": "systems-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231821584?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "In this presentation, I will talk about my firsthand experience dealing with the unique challenges of running Kafka at a massive scale. If you ever thought that running Kafka is difficult, this talk may change your mind and provide you with valuable insights into how to configure a Kafka cluster efficiently, how to manage Kafka for enterprise customers and how to measure, monitor and maintain the Quality of Kafka Service. Our production Kafka cluster runs over 1500+ VMs, and serves over 10 GBPS data spread across hundreds of topics for multiple teams across Microsoft. We built a self-serve Kafka management service to make the process manageable and scalable across many teams. In this talk, I will also share insights about running Kafka in Private vs multi-tenant mode, supporting failover and disaster recovery requirements, and how to make Kafka Compliant with regulatory certifications such as ISO, SOC, FEDRAMP, etc."},
{"speakers": [{"bio": "", "corp": "IBM", "name": "Edoardo Comar, Senior Developer"}, {"bio": "", "corp": "IBM", "name": "Andrew Schofield, Chief Architect, Hybrid Cloud Messaging"}], "base_fname": "820371397", "title": "Kafka and the Polyglot Programmer", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/DM47IcG3lJV4Tp"}, "tag": "systems-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231822733?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "An Overview of the Kafka clients ecosystem. APIs \u2013 wire protocol clients \u2013 higher level clients (Streams) \u2013 REST Languages (with simple snippets \u2013 full examples in GitHub) \u2013 the most developed clients \u2013 Java and C/C++ \u2013 the librdkafka wrappers node-rdkafka, python, GO, C# \u2013 why use wrappers Shell scripted Kafka ( e.g. custom health checks) kafkacat Platform gotchas (e.g. SASL on Win32)"},
{"speakers": [{"bio": "", "corp": "Confluent", "name": "Matthias Sax, Engineer"}], "base_fname": "827559383", "title": "Query the Application, Not a Database: \u201cInteractive Queries\u201d in Kafka\u2019s Streams API", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/n1fqQEi7I2F67i"}, "tag": "streams-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231821194?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "Kafka Streams allows to build scalable streaming apps without a cluster. This \u201cCluster-to-go\u201d approach is extended by a \u201cDB-to-go\u201d feature: Interactive Queries allows to directly query app internal state, eliminating the need for an external DB to access this data. This avoids redundantly stored data and DB update latency, and simplifies the overall architecture, e.g., for micro-services."},
{"speakers": [{"bio": "", "corp": "Confluent", "name": "Benjamin Stopford, Engineer"}], "base_fname": "827548800", "title": "Building Event-Driven Services with Stateful Streams", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/opM73EjWv8jMIc"}, "tag": "streams-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231819972?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "Event Driven Services come in many shapes and sizes from tiny event driven functions that dip into an event stream, right through to heavy, stateful services which can facilitate request response. This practical talk makes the case for building this style of system using Stream Processing tools. We also walk through a number of patterns for how we actually put these things together."},
{"speakers": [{"bio": "", "corp": "NTT-DATA", "name": "Masaru Dobashi, Chief Engineer"}, {"bio": "", "corp": "Inc.", "name": "Shingo Omura, Software Engineer, Chatwork"}], "base_fname": "820379181", "title": "Worldwide Scalable and Resilient Messaging Services with Kafka and Kafka Streams", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/9RJBtd9YMxE3a7"}, "tag": "systems-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231824430?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "ChatWork is a worldwide communication service, which holds 110k+ of customer organizations. In 2016, we have developed a new scalable infrastructure based on the idea of CQRS and Event Sourcing using Kafka and Kafka Streams combined with Akka and HBase. In this session, we talk about the concept of this architecture and lessons learned in production use cases."},
{"speakers": [{"bio": "", "corp": "LINE Corporation", "name": "Yuto Kawamura, Software Engineer"}], "base_fname": "820369469", "title": "One Day, One Data Hub, 100 Billion Messages: Kafka at LINE", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/nrtofvLG1pYlUT"}, "tag": "systems-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231822125?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "LINE is a messaging service with 200+ million active users. I will introduce why we feed 100+ billion daily messages into Kafka and how various systems such as data sync, abuse detection and analysis are depending on and leveraging it. It will be also introduced how we leverage dynamic tracing tools like SystemTap to inspect broker\u2019s performance on production system, which led me to fix KAFKA-4614."},
{"speakers": [{"bio": "", "corp": "LinkedIn", "name": "Todd Palino, Staff Site Reliability Engineer"}], "base_fname": "820369533", "title": "Running Kafka for Maximum Pain", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/vAisGQXMJPP9W1"}, "tag": "systems-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231822124?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "Kafka makes so many things easier to do, from managing metrics to processing streams of data. Yet it seems that so many things we have done to this point in configuring and managing it have been object studies in how to make our lives, as the plumbers who keep the data flowing, more difficult than they have to be. What are some of our favorites?\n\n\n \tKafka without access controls\n \tMulti-tenant clusters with no capacity controls\n \tWorrying about message schemas\n \tMirrorMaker inefficiencies\n \tHope and pray log compaction\n \tConfigurations as shared secrets\n \tOne-way upgrades\n\nWe\u2019ve made a lot of progress over the last few years improving the situation, in part by focusing some of this incredibly talented community towards operational concerns. We\u2019ll talk about the big mistakes you can avoid when setting up multi-tenant Kafka, and some that you still can\u2019t. And we will talk about how to continue down the path of marrying the hot, new features with operational stability so we can all continue to come back here every year to talk about it."},
{"speakers": [{"bio": "", "corp": "BlueData", "name": "Nanda Vijaydev, Senior Director, Solutions Management"}], "base_fname": "820372402", "title": "Best Practices for Running Kafka on Docker Containers", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/i7ej1iHI16Senz"}, "tag": "systems-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231822967?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "Docker containers provide an ideal foundation for running Kafka-as-a-Service on-premises or in the public cloud. However, using Docker containers in production environments poses some challenges \u2013 including container management, scheduling, network configuration and security, and performance. In this session, we\u2019ll share lessons learned from implementing Kafka-as-a-Service with Docker containers."},
{"speakers": [{"bio": "", "corp": "Confluent", "name": "Sriram Subramanian, Director, Platform & Infra Engineering"}], "base_fname": "820370266", "title": "Running Kafka as a Service at Scale", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/eYe6P57LSth5Il"}, "tag": "systems-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231822532?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "Apache Kafka is recognized as the world\\u2019s leading real-time, fault tolerant, highly scalable stream platform. It is adopted very widely across thousands of companies worldwide from web giants like LinkedIn, Netflix, Uber to large enterprises like Apple, Cisco, Goldman Sachs and more.\n\nIn this talk, we will look at what Confluent has done along with the help from the community to enable running Kafka as a fully managed service. The engineers at Confluent spent multiple years running Kafka as a service and learnt very valuable lessons in that process. They understood how things are very different when you run in a controlled environment inside a single company vs running Kafka for thousands of companies. This talk will go over those valuable lessons and what we have built in Kafka as a result which is available to all Kafka users as part of Confluent Cloud."},
{"speakers": [{"bio": "", "corp": "Confluent", "name": "Guozhang Wang, Engineer"}], "base_fname": "820376303", "title": "Exactly-once Stream Processing with Kafka Streams", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/Hz06dvaLuD5Bat"}, "tag": "systems-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231823793?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "In this talk, we present the recent additions to Kafka to achieve exactly-once semantics within its Streams API for stream processing use cases. This is achieved by leveraging the underlying idempotent and transactional client features. The main focus will be the specific semantics that Kafka distributed transactions enable in Streams and the underlying mechanics to let Streams scale efficiently."},
{"speakers": [{"bio": "", "corp": "ThoughtWorks", "name": "Jeroen Soeters, Lead Developer"}], "base_fname": "827566034", "title": "Fast Data in Supply Chain Planning", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/bsUhYtfsbPXKXo"}, "tag": "streams-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231820983?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "We are migrating one of the top 3 consumer packaged goods companies from a batch-oriented systems architecture to a streaming micro services platform. In this talk I\u2019ll explain how we leverage the Lightbend reactive stack and Kafka to achieve this and how the 4 Kafka APIs fit in our architecture. Also I explain why Kafka Streams <3 Enterprise Integration Patterns."},
{"speakers": [{"bio": "", "corp": "Zalando", "name": "Hunter Kelly, Senior Software/Data Engineer"}], "base_fname": "820362140", "title": "Real-Time Document Rankings with Kafka Streams", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/twDsiBxABvdluX"}, "tag": "streams-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231820807?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "The HITS algorithm creates a score for documents; one is \u201chubbiness\u201d, the other is \u201cauthority\u201d. Usually this is done as a batch operation, working on all the data at once. However, with careful consideration, this can be implemented in a streaming architecture using KStreams and KTables, allowing efficient real time sampling of rankings at a frequency appropriate to the specific use case."},
{"speakers": [{"bio": "", "corp": "Google", "name": "Frances Perry, Software Engineer"}], "base_fname": "827558724", "title": "Portable Streaming Pipelines with Apache Beam", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/2esrNdSMeAAmRV"}, "tag": "streams-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231820628?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "Much as SQL stands as a lingua franca for declarative data analysis, Apache Beam aims to provide a portable standard for expressing robust, out-of-order data processing pipelines in a variety of languages across a variety of platforms. By cleanly separating the user\u2019s processing logic from details of the underlying execution engine, the same pipelines will run on any Apache Beam runtime environment, whether it\u2019s on-premise or in the cloud, on open source frameworks like Apache Spark or Apache Flink, or on managed services like Google Cloud Dataflow. In this talk, I will:\n\n\n \tBriefly, introduce the capabilities of the Beam model for data processing and integration with IO connectors like Apache Kafka.\n \tDiscuss the benefits Beam provides regarding portability and ease-of-use.\n \tDemo the same Beam pipeline running on multiple runners in multiple deployment scenarios (e.g. Apache Flink on Google Cloud, Apache Spark on AWS, Apache Apex on-premise).\n \tGive a glimpse at some of the challenges Beam aims to address in the future."},
{"speakers": [{"bio": "", "corp": "Confluent", "name": "Nick Dearden, Director of Engineering"}], "base_fname": "820359575", "title": "Kafka Stream Processing for Everyone with KSQL", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/NWi8HZ7DEeJSx4"}, "tag": "streams-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231820385?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "The rapidly expanding world of stream processing can be daunting, with new concepts (various types of time semantics, windowed aggregates, changelogs, and so on) and programming frameworks to master. KSQL is a new open-source project which aims to simplify all this and make stream processing available to everyone."},
{"speakers": [{"bio": "", "corp": "IBM", "name": "Holden Karau, Principal Software Engineer"}], "base_fname": "820358438", "title": "Streaming Processing in Python \u2013 10 ways to avoid summoning Cuthulu", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/CHTsn3hlibDeZg"}, "tag": "streams-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231820207?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "<3 Python & want to process data from Kafka? This talk will look how to make this awesome. In many systems the traditional approach involves first reading the data into the JVM and then passing the data to Python, which can be a little slow, and on a bad day results in almost impossible to debug. This talk will look at how to be more awesome in Spark & how to do this in Kafka Streams."},
{"speakers": [{"bio": "", "corp": "Etsy", "name": "Nikki Thean, Staff Engineer"}], "base_fname": "820300772", "title": "Streaming Data Applications on Docker", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/1X9OhLfsHMB1mc"}, "tag": "use-case-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231807708?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "Should you containerize your Kafka Streams or Kafka Connect apps? I\u2019ll answer this popular question by describing the evolution of streaming platforms at Etsy, which we\u2019ve run on both Docker and bare metal, and what we learned on the way. Attendees will learn about the benefits and drawbacks of each approach, plus some tips and best practices for running your Kafka apps in production."},
{"speakers": [{"bio": "", "corp": "Criteo", "name": "Oleksandr Kaidannik, Software Engineer"}], "base_fname": "820302419", "title": "Infrastructure for Streaming Applications in Criteo", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/uBrVAAcMrQ4Jbr"}, "tag": "use-case-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231808159?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "We created specialized infrastructure for Kafka Streams in each DC. It allows us fast and easy bootstrap stream applications for everyone in Criteo. Its includes next parts: Replication based on Kafka Connect Kafka Connect on Mesos Kafka Streams Application on Mesos Monitoring of Kafka Streams application Kafka Configuration as Code Protobuf schemas and deployment"},
{"speakers": [{"bio": "", "corp": "Shopify", "name": "Sam Obeid, Senior Production Engineer"}], "base_fname": "820289065", "title": "Shopify Flash-Sales and Apache Kafka", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/8g5kTkO73lycLe"}, "tag": "use-case-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231805287?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "Shopify is a leading e-commerce platform with 325+ thousand merchants and peak traffic of over 4 million rpm. We enable our merchants to run flash sales, which can double or triple traffic for a short period of time. This talk will take you through the engineering challenges of enabling Shopify to run flash sales, and how Apache Kafka plays a crucial role in supporting this feature."},
{"speakers": [{"bio": "", "corp": "Capital One", "name": "Vijay Pasam, Senior Software Development Manager"}, {"bio": "", "corp": "Capital One", "name": "Japan Bhatt, Master Software Engineer"}], "base_fname": "820287280", "title": "Real Time Streaming Platform for Communications and Beyond", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/4XygW3lDDp5ZC3"}, "tag": "use-case-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231804668?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "The focus of this session is to share our experience of using Kafka in reinventing CapitalOne auto finance customer communications infrastructure. We will share our technology selection process, system architecture to build a highly resilient and available system, cloud native design and lessons learnt. We will also review our journey of moving from batch to real time event driven system."},
{"speakers": [{"bio": "", "corp": "Riot Games", "name": "Singe Graham, Systems Engineer"}], "base_fname": "820290041", "title": "Riot\u2019s Journey to Global Kafka Aggregation", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/FjDYeyM0RmxS6J"}, "tag": "use-case-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231805421?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "With over 100 million monthly players and presence in over 20 data centers globally, League of Legends generates an immense amount of operational and analytical data that has, until recently, been siloed where it was generated or delayed via slow ETLs. In this talk, Riot Games will share their challenges and victories of rolling out a globally aggregated Kafka pipeline to overcome these limitations"},
{"speakers": [{"bio": "", "corp": "WePay", "name": "Moira Tagle, Senior Software Engineer"}], "base_fname": "820299661", "title": "Database Streaming At WePay With Kafka and Debezium", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/1mrsrFrhKYFRFp"}, "tag": "use-case-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231807459?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "This talk will focus on how database streaming is essential to WePay\u2019s infrastructure, and the many functions that database streaming serves. It will also provide information on how the database streaming infrastructure was created and is managed so that others can leverage WePay\u2019s work to develop their own database streaming solutions."},
{"speakers": [{"bio": "", "corp": "Cern", "name": "Martin Marquez, Data Scientist & Data Streaming Services Project Leader"}], "base_fname": "820288458", "title": "Accelerating Particles to Explore the Mysteries of the Universe and How Kafka Can Help on That", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/zMIMuc0GKsCSt"}, "tag": "use-case-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231805071?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "CERN uses the world\u2019s largest and most complex scientific instruments to prove the fundamental structure of the universe. The organization is deploying a data streaming infrastructure, based on Kafka and IaaS cloud, to make its operations more scalable and efficient. This session expounds the motivations, selected architecture, challenging use cases and shares ours lessons learned and future plans."},
{"speakers": [{"bio": "", "corp": "Netflix", "name": "Allen Wang, Senior Software Engineer"}], "base_fname": "820286995", "title": "Multi-Tenant, Multi-Cluster and Hierarchical Kafka Messaging Service", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/lat3FudhAeVe6q"}, "tag": "use-case-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231804669?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "Kafka is easy to set up as a messaging service and serves the purpose well. However, it gets complicated in a multi-tenant environment, where users have different SLA on availability, durability and latency. As traffic grows, managing a huge and monolithic Kafka cluster in a cloud environment has been proved to be problematic and hard to scale.\nAt Netflix, our Kafka messaging system evolves into a multi-cluster and hierarchical service where it can serve over a trillion messages per day. Topics are allocated in either shared or dedicated clusters according to SLA requirements and can be migrated across clusters. Infrastructure routers connect Kafka clusters and provide hierarchical access to data. With the help of enhanced client libraries and proxies, clients interact with the service using higher level APIs and abstracted access points. Kafka deployments are transparent from clients. Enabled by our client libraries and Netflix cloud infrastructure, we are able to mitigate Kafka cluster level failures with our Kafka failover which is also transparent to the clients.\nIn this talk, we are going to discuss why this architecture is necessary and how we have implemented it with essential components including management and self-service tools, infrastructure routers, client libraries, proxies and monitoring service."},
{"speakers": [{"bio": "", "corp": "NuCypher", "name": "Michael Egorov, Co-founder and CTO"}], "base_fname": "820356561", "title": "Body Armor for Distributed System", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/k5v9ububiyvF1s"}, "tag": "pipeline-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231819762?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "We show a way to make Kafka end-to-end encrypted. It means that data is ever decrypted only at the side of producers and consumers of the data. The data is never decrypted broker-side. Importantly, all Kafka clients have their own encryption keys. There is no pre-shared encryption key. Our approach can be compared to TLS implemented for more than two parties connected together."},
{"speakers": [{"bio": "", "corp": "Yelp", "name": "Justin Cunningham, Technical Lead, Software Engineering"}], "base_fname": "820355703", "title": "Billions of Messages a Day \u2013 Yelp\u2019s Real-time Data Pipeline", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/91EYp6QprgQwAH"}, "tag": "pipeline-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231819565?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "Yelp moved quickly into building out a comprehensive service oriented architecture, and before long had over 100 data-owning production services. Distributing data across an organization creates a number of issues, particularly around the cost of joining disparate data sources, dramatically increasing the complexity of bulk data applications. Straightforward solutions like bulk data APIs and sharing data snapshots have significant drawbacks. Yelp\u2019s Data Pipeline makes it easier for these services to communicate with each other, provides a framework for real-time data processing, and facilitates high-performance bulk data applications \u2013 making large SOAs easier to work with. The Data Pipeline provides a series of guarantees that makes it easy to create universal data producers and consumers that can be mashed up into interesting real-time data flows. We\u2019ll show how a few simple services at Yelp lay the foundation that powers everything from search to our experimentation framework."},
{"speakers": [{"bio": "", "corp": "Blizzard", "name": "Jeff Field, Systems Engineer"}], "base_fname": "820354900", "title": "How Blizzard Used Kafka to Save Our Pipeline (and Azeroth)", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/p61bQue7XUJHy"}, "tag": "pipeline-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231819363?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "When Blizzard started sending gameplay data to Hadoop in 2013, we went through several iterations before settling on Flumes in many data centers around the world reading from RabbitMQ and writing to central flumes in our Los Angeles datacenter. While this worked at first, by 2015 we were hitting problems scaling to the number of events required. This is how we used Kafka to save our pipeline."},
{"speakers": [{"bio": "", "corp": "Confluent", "name": "Randall Hauch, Engineer"}], "base_fname": "820353906", "title": "Kafka Connect Best Practices \u2013 Advice from the Field", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/bPMu6Fr8Kj0Ohq"}, "tag": "pipeline-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231819142?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "This talk will review the Kafka Connect Framework and discuss building data pipelines using the library of available Connectors. We\u2019ll deploy several data integration pipelines and demonstrate :\n\n \tbest practices for configuring, managing, and tuning the connectors\n \ttools to monitor data flow through the pipeline\n \tusing Kafka Streams applications to transform or enhance the data in flight."},
{"speakers": [{"bio": "", "corp": "New Relic", "name": "Amy Boyle, Software Engineer"}], "base_fname": "820309476", "title": "From Scaling Nightmare to Stream Dream : Real-time Stream Processing at Scale", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/zuefZl5icv9EX7"}, "tag": "pipeline-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231809625?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "On the events pipeline team at New Relic, Kafka is the thread that stitches our micro-service architecture together. We receive billions of monitoring events an hour, which customers rely on us to alert on in real-time. Facing a ten fold+ growth in the system, learn how we avoided a costly scaling nightmare by switching to a streaming system, based on Kafka. We follow a DevOps philosophy at New Relic. Thus, I have a personal stake in how well our systems perform. If evaluation deadlines are missed, I loose sleep and customers loose trust. Without necessarily setting out to from the start, we\u2019ve gone all in, using Kafka as the backbone of an event-driven pipeline, as a datastore, and for streaming updates to the system. Hear about what worked for us, what challenges we faced, and how we continue to scale our applications."},
{"speakers": [{"bio": "", "corp": "HomeAway", "name": "Praveen Hirsave, Director Cloud Engineering"}, {"bio": "", "corp": "HomeAway", "name": "Rene Parra, Chief Architect"}], "base_fname": "820305534", "title": "DNS for Data: The Need for a Stream Registry", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/1GxrX05gY6Iaml"}, "tag": "pipeline-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231808807?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "As organizations increasingly adopt streaming platforms such as kafka, the need for visibility and discovery has become paramount. Increasingly, with the advent of self-service streaming and analytics, a need to increase on overall speed, not only on time-to-signal, but also on reducing times to production is becoming the difference between winners and losers. Beyond Kafka being at the core of successful streaming platforms, there is a need for a stream registry. Come to this session to find out how HomeAway is solving this with a \u201cjust right\u201d approach to governance."},
{"speakers": [{"bio": "", "corp": "Confluent", "name": "Gwen Shapira, Product Manager"}], "base_fname": "823890717", "title": "One Data Center is Not Enough: Scaling Apache Kafka Across Multiple Data Centers", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/1N4apZVEwRRZkp"}, "tag": "pipeline-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231808426?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "You have made the transition from single machines and one-off solutions to distributed infrastructure in your data center powered by Apache Kafka. But what if one data center is not enough? In this session, we review resilient data pipelines with Apache Kafka that span multiple data centers. We provide an overview of best practices and common patterns including key areas such as architecture and data replication as well as disaster scenarios and failure handling."},
{"speakers": [{"bio": "", "corp": "StreamSets Inc.", "name": "Pat Patterson, Community Champion"}], "base_fname": "820301685", "title": "Efficient Schemas in Motion with Kafka and Schema Registry", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/I7M7mwksWlZXie"}, "tag": "pipeline-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231807960?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "Apache Avro allows data to be self-describing, but carries an overhead when used with message queues such as Apache Kafka. Confluent\u2019s open source Schema Registry integrates with Kafka to allow Avro schemas to be passed \u2018by reference\u2019, minimizing overhead, and can be used with any application that uses Avro. Learn about Schema Registry, using it with Kafka, and leveraging it in your application."},
{"speakers": [{"bio": "", "corp": "Funding Circle", "name": "Charles Reese, Senior Software Engineer"}, {"bio": "", "corp": "Funding Circle", "name": "Matthias Margush, Software Engineer"}], "base_fname": "820365145", "title": "Building Stateful Financial Applications with Kafka Streams", "slide": {"dl_link": "", "src_link": "https://www.slideshare.net/slideshow/embed_code/key/tnCnPkTsAkwQXJ"}, "tag": "streams-track", "video": {"dl_link": "", "src_link": "https://player.vimeo.com/video/231821392?color=ff671f&title=0&byline=0&portrait=0"}, "desc": "At Funding Circle, we are building a global lending platform with Apache Kafka and Kafka Streams to handle high volume, real-time processing with rapid clearing times similar to a stock exchange. In this talk, we will provide an overview of our system architecture and summarize key results in edge service connectivity, idempotent processing, and migration strategies."}
]
